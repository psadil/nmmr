<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Bayesian Hierarchical Deming Regression • nmmr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><meta property="og:title" content="Bayesian Hierarchical Deming Regression">
<meta property="og:description" content="nmmr">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-VX8V7SDMRL"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VX8V7SDMRL');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">nmmr</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="Unreleased version">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/articles/deming-regression.html">Bayesian Hierarchical Deming Regression</a>
    </li>
    <li>
      <a href="../../articles/articles/orthogonal.html">Orthogonal Regression</a>
    </li>
    <li>
      <a href="../../articles/articles/vtf.html">vtf</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/psadil/nmmr/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="deming-regression_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Bayesian Hierarchical Deming Regression</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/psadil/nmmr/blob/master/vignettes/articles/deming-regression.Rmd"><code>vignettes/articles/deming-regression.Rmd</code></a></small>
      <div class="hidden name"><code>deming-regression.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://psadil.github.io/nmmr/">nmmr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org">tidyr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://forcats.tidyverse.org">forcats</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></code></pre></div>
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>The <code>vignette("orthogonal")</code> presented a quick, non-parametric approach for checking neuromodulation based on a scatter plot of voxel activity at high- versus low-contrast. However, that method required an <em>ad hoc</em> preprocessing step, excluding poorly tuned voxels. Without this preprocessing, the estimated slopes were too variable. To obviate the need for filtering voxels, this vignette covers another set of functions that implement the scatter plot idea in a Bayesian hierarchical framework.</p>
</div>
<div id="bayesian-hierarchical-deming-regression" class="section level1">
<h1 class="hasAnchor">
<a href="#bayesian-hierarchical-deming-regression" class="anchor"></a>Bayesian Hierarchical Deming Regression</h1>
<div id="the-model" class="section level2">
<h2 class="hasAnchor">
<a href="#the-model" class="anchor"></a>The Model</h2>
<p>The model is very similar to the model underlying orthogonal regression, but for two important changes. First, the model is hierarchical. That is, whereas we previously ran a separate orthogonal regression on each voxel, we now estimate each of the separate slope, intercept, and noise terms in a single regression model<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. Second, we relax the assumption that the variances in both observed variables (e.g., voxel activity at high and low contrast) are equal<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.</p>
<p>The paper has full details of the model, but a <a href="https://en.wikipedia.org/wiki/Plate_notation">plate diagram</a> for the model is is reproduced here.</p>
<div class="figure">
<img src="deming-regression-model.png" alt='Schematic of the Bayesian model. Filled square nodes indicate priors, open circles are estimated parameters, the shaded circles are observed data, and the open diamond is the result of a deterministic function of the parameters. Nodes are grouped with the square "plates", indicating over which subsets of the data the node is replicated. The distribution assigned to each node is listed to the right of the diagram. $N(\mu,\sigma)$ is a normal with location $\mu$ and scale $\sigma$, and $TN(\mu,\sigma)$ is a normal with the same parameters, truncated below at $\mu$. Each equation in the upper right is associated with an arrow in the diagram, describing a relationship between nodes.' width="100%"><p class="caption">
Schematic of the Bayesian model. Filled square nodes indicate priors, open circles are estimated parameters, the shaded circles are observed data, and the open diamond is the result of a deterministic function of the parameters. Nodes are grouped with the square “plates”, indicating over which subsets of the data the node is replicated. The distribution assigned to each node is listed to the right of the diagram. <span class="math inline">\(N(\mu,\sigma)\)</span> is a normal with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\sigma\)</span>, and <span class="math inline">\(TN(\mu,\sigma)\)</span> is a normal with the same parameters, truncated below at <span class="math inline">\(\mu\)</span>. Each equation in the upper right is associated with an arrow in the diagram, describing a relationship between nodes.
</p>
</div>
</div>
<div id="application-to-data" class="section level2">
<h2 class="hasAnchor">
<a href="#application-to-data" class="anchor"></a>Application to data</h2>
<div id="data-prep" class="section level3">
<h3 class="hasAnchor">
<a href="#data-prep" class="anchor"></a>Data Prep</h3>
<p>As for the orthogonal regression functions, the data need to be in a wider format. Additionally, the tuning variable (e.g., <code>orientation</code>) should be converted into a <code>factor</code>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sub02_wide</span> <span class="op">&lt;-</span> <span class="va">sub02</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_wider.html">pivot_wider</a></span><span class="op">(</span>names_from <span class="op">=</span> <span class="va">contrast</span>, values_from <span class="op">=</span> <span class="va">y</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>orientation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">orientation</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>For the purposes of this vignette, we reduce the dataset down to just 100 voxels. This is only to speed up the estimation process.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">small</span> <span class="op">&lt;-</span> <span class="va">sub02_wide</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">orientation</span>, <span class="va">run</span>, <span class="va">ses</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice_head</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>voxel <span class="op">=</span> <span class="fu"><a href="https://forcats.tidyverse.org/reference/fct_drop.html">fct_drop</a></span><span class="op">(</span><span class="va">voxel</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span> </code></pre></div>
</div>
<div id="stan-code" class="section level3">
<h3 class="hasAnchor">
<a href="#stan-code" class="anchor"></a>Stan Code</h3>
<p>The model can be implemented by initializing an object provided by the <code>nmmr</code> package of class <a href="https://psadil.github.io/nmmr/reference/Deming.html"><code>Deming</code></a>, using the <a href="https://psadil.github.io/nmmr/reference/Deming.html#method-new"><code>$new()</code></a> method. This method takes a dataset and the names of the columns with the two dependent variables (e.g., <code>low</code> and <code>high</code>). Additionally, the class needs to know which column contains the tuning variable (e.g., <code>orientation</code>) and the column indexing voxel (e.g., <code>voxel</code>).</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m</span> <span class="op">&lt;-</span> <span class="va"><a href="../../reference/Deming.html">Deming</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">small</span>, <span class="va">low</span>, <span class="va">high</span>, tuning_var <span class="op">=</span> <span class="va">orientation</span>, voxel_var <span class="op">=</span> <span class="va">voxel</span><span class="op">)</span></code></pre></div>
<p>The newly created object, <code>m</code>, is an <a href="https://r6.r-lib.org/"><code>R6</code></a> object of class <a href="https://psadil.github.io/nmmr/reference/Deming.html"><code>Deming</code></a>. It can be thought of as a wrapper around an instance of a <code><a href="https://mc-stan.org/cmdstanr/reference/CmdStanModel.html">cmdstanr::CmdStanModel</a></code> class, but one which prepares the data for sampling. The actual model is contained in a field of <code>m</code> called <code>cmdstanmodel</code>. The underlying Stan model can be accessed with the <a href="https://mc-stan.org/cmdstanr/reference/CmdStanModel.html#methods"><code>$print()</code></a> method of the <code>cmdstanmodel</code> field.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">m</span><span class="op">$</span><span class="va">cmdstanmodel</span>
<span class="co">#&gt; data {</span>
<span class="co">#&gt;   int&lt;lower=1&gt; n;  // total number of observations</span>
<span class="co">#&gt;   int n_voxel;</span>
<span class="co">#&gt;   int&lt;lower=1, upper=n_voxel&gt; voxel[n];</span>
<span class="co">#&gt;   int n_tuning;</span>
<span class="co">#&gt;   int&lt;lower=1, upper=n_tuning&gt; tuning[n];</span>
<span class="co">#&gt;   int&lt;lower=1, upper=n_tuning*n_voxel&gt; voxel_tuning[n]; // index to pick out from matrix of tuning x voxel</span>
<span class="co">#&gt;   vector[n] y;  // response variable (high)</span>
<span class="co">#&gt;   vector[n] x;  // noisy values (low)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   // priors</span>
<span class="co">#&gt;   vector[2] prior_z_mu_mu;</span>
<span class="co">#&gt;   vector[2] prior_z_mu_sigma;</span>
<span class="co">#&gt;   vector[2] prior_z_sigma_mu;</span>
<span class="co">#&gt;   vector[2] prior_z_sigma_sigma;</span>
<span class="co">#&gt;   vector[2] prior_x_sigma_mu;</span>
<span class="co">#&gt;   vector[2] prior_x_sigma_sigma;</span>
<span class="co">#&gt;   vector[2] prior_y_sigma_mu;</span>
<span class="co">#&gt;   vector[2] prior_y_sigma_sigma;</span>
<span class="co">#&gt;   vector[2] prior_g_mu;</span>
<span class="co">#&gt;   vector[2] prior_g_sigma;</span>
<span class="co">#&gt;   vector[2] prior_a_mu;</span>
<span class="co">#&gt;   vector[2] prior_a_sigma;</span>
<span class="co">#&gt; }</span>
<span class="co">#&gt; parameters {</span>
<span class="co">#&gt;   real&lt;lower=0&gt; g_sigma;</span>
<span class="co">#&gt;   real g_mu;</span>
<span class="co">#&gt;   vector&lt;multiplier=g_sigma, offset=g_mu&gt;[n_voxel] g;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; a_sigma;</span>
<span class="co">#&gt;   real a_mu;</span>
<span class="co">#&gt;   vector&lt;multiplier=a_sigma, offset=a_mu&gt;[n_voxel] a;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; z_mu_sigma;</span>
<span class="co">#&gt;   real z_mu_mu;</span>
<span class="co">#&gt;   row_vector[n_voxel] z_mu;</span>
<span class="co">#&gt;   matrix[n_tuning, n_voxel] z_raw;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; z_sigma_sigma;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; z_sigma_mu;</span>
<span class="co">#&gt;   vector&lt;lower=-z_sigma_mu/z_sigma_sigma&gt;[n_voxel] z_sigma_raw;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; x_sigma_sigma;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; x_sigma_mu;</span>
<span class="co">#&gt;   vector&lt;lower=0&gt;[n_voxel] x_sigma;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; y_sigma_sigma;</span>
<span class="co">#&gt;   real&lt;lower=0&gt; y_sigma_mu;</span>
<span class="co">#&gt;   vector&lt;lower=0&gt;[n_voxel] y_sigma;</span>
<span class="co">#&gt; }</span>
<span class="co">#&gt; transformed parameters{</span>
<span class="co">#&gt;   vector[n_tuning*n_voxel] zeta;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   {</span>
<span class="co">#&gt;     matrix[n_tuning, n_voxel] z;</span>
<span class="co">#&gt;     vector[n_voxel] z_sigma = z_sigma_mu + z_sigma_raw * z_sigma_sigma;</span>
<span class="co">#&gt;     for (v in 1:n_voxel) z[,v] = z_sigma[v] * z_raw[,v] + z_mu[v];</span>
<span class="co">#&gt;     zeta = to_vector(z);</span>
<span class="co">#&gt;   }</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; }</span>
<span class="co">#&gt; model {</span>
<span class="co">#&gt;   z_mu_mu ~ normal(prior_z_mu_mu[1], prior_z_mu_mu[2]);</span>
<span class="co">#&gt;   z_mu_sigma ~ normal(prior_z_mu_sigma[1], prior_z_mu_sigma[2]);</span>
<span class="co">#&gt;   z_mu ~ normal(z_mu_mu, z_mu_sigma);</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   to_vector(z_raw) ~ std_normal();</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   z_sigma_mu ~ normal(prior_z_sigma_mu[1], prior_z_sigma_mu[2]);</span>
<span class="co">#&gt;   z_sigma_sigma ~ normal(prior_z_sigma_sigma[1], prior_z_sigma_sigma[2]);</span>
<span class="co">#&gt;   z_sigma_raw ~ std_normal();</span>
<span class="co">#&gt;   target += -normal_lccdf(-z_sigma_mu/z_sigma_sigma | 0, 1)*n_voxel;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   x_sigma_mu ~ normal(prior_x_sigma_mu[1], prior_x_sigma_mu[2]);</span>
<span class="co">#&gt;   x_sigma_sigma ~ normal(prior_x_sigma_sigma[1], prior_x_sigma_sigma[2]);</span>
<span class="co">#&gt;   x_sigma ~ normal(x_sigma_mu, x_sigma_sigma);</span>
<span class="co">#&gt;   target += -normal_lccdf(0 | x_sigma_mu, x_sigma_sigma) * n_voxel;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   y_sigma_mu ~ normal(prior_y_sigma_mu[1], prior_y_sigma_mu[2]);</span>
<span class="co">#&gt;   y_sigma_sigma ~ normal(prior_y_sigma_sigma[1], prior_y_sigma_sigma[2]);</span>
<span class="co">#&gt;   y_sigma ~ normal(y_sigma_mu, y_sigma_sigma);</span>
<span class="co">#&gt;   target += -normal_lccdf(0 | y_sigma_mu, y_sigma_sigma) * n_voxel;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   g_mu ~ normal(prior_g_mu[1], prior_g_mu[2]);</span>
<span class="co">#&gt;   g_sigma ~ normal(prior_g_sigma[1], prior_g_sigma[2]);</span>
<span class="co">#&gt;   g ~ normal(g_mu, g_sigma);</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   a_mu ~ normal(prior_a_mu[1], prior_a_mu[2]);</span>
<span class="co">#&gt;   a_sigma ~ normal(prior_a_sigma[1], prior_a_sigma[2]);</span>
<span class="co">#&gt;   a ~ normal(a_mu, a_sigma);</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   // likelihood</span>
<span class="co">#&gt;   x ~ normal(zeta[voxel_tuning], x_sigma[voxel]);</span>
<span class="co">#&gt;   y ~ normal(a[voxel] + zeta[voxel_tuning] .* g[voxel], y_sigma[voxel]);</span>
<span class="co">#&gt; }</span></code></pre></div>
<p>Note that, in the model, the names of the parameters were chosen to match the names in the plate diagram, above. For example, the parameter <code>g</code> is the voxel-specific slope. The hierarchy on the slope assumes that each individual voxel’s slope comes from a population distribution, which in this case is normal with mean <code>g_mu</code> (written in the diagram <span class="math inline">\(\mu^g\)</span>) and standard deviation <code>g_sigma</code> (written in the diagram as <span class="math inline">\(\sigma^g\)</span>).</p>
<p>The <code>m</code> object contains a method called <a href="https://psadil.github.io/nmmr/reference/Deming.html#method-sample"><code>$sample()</code></a>, which accepts all of the arguments as the <a href="https://mc-stan.org/cmdstanr/reference/model-method-sample.html"><code>$sample()</code></a> method of a <code><a href="https://mc-stan.org/cmdstanr/reference/CmdStanModel.html">cmdstanr::CmdStanModel</a></code>. Here is how to generate samples from the posterior distribution, running two chains in parallel and setting the random number generator seed.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># fewer samples run for the sake of a quicker vignette</span>
<span class="co"># In a real analysis, you would probably want at least 4 chains with </span>
<span class="co"># 1000 samples each</span>
<span class="va">fit</span> <span class="op">&lt;-</span> <span class="va">m</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span>
  chains <span class="op">=</span> <span class="fl">2</span>, 
  parallel_chains <span class="op">=</span> <span class="fl">2</span>, 
  seed <span class="op">=</span> <span class="fl">1</span>,
  iter_sampling <span class="op">=</span> <span class="fl">100</span>,
  iter_warmup <span class="op">=</span> <span class="fl">500</span><span class="op">)</span>
<span class="co">#&gt; Running MCMC with 2 parallel chains...</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Chain 1 Iteration:   1 / 600 [  0%]  (Warmup)</span>
<span class="co">#&gt; Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 1 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 1</span>
<span class="co">#&gt; Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 1 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 1</span>
<span class="co">#&gt; Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 1 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 1</span>
<span class="co">#&gt; Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 1 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 1</span>
<span class="co">#&gt; Chain 1 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 1 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 1 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 1 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 1</span>
<span class="co">#&gt; Chain 2 Iteration:   1 / 600 [  0%]  (Warmup)</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 31, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 31, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 28, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:</span>
<span class="co">#&gt; Chain 2 Exception: offset_multiplier_constrain: multiplier is 0, but must be positive finite! (in '/tmp/Rtmpw51K6K/model-33a3718a1cd3.stan', line 31, column 2 to column 53)</span>
<span class="co">#&gt; Chain 2 If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,</span>
<span class="co">#&gt; Chain 2 but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.</span>
<span class="co">#&gt; Chain 2</span>
<span class="co">#&gt; Chain 2 Iteration: 100 / 600 [ 16%]  (Warmup) </span>
<span class="co">#&gt; Chain 1 Iteration: 100 / 600 [ 16%]  (Warmup) </span>
<span class="co">#&gt; Chain 2 Iteration: 200 / 600 [ 33%]  (Warmup) </span>
<span class="co">#&gt; Chain 1 Iteration: 200 / 600 [ 33%]  (Warmup) </span>
<span class="co">#&gt; Chain 2 Iteration: 300 / 600 [ 50%]  (Warmup) </span>
<span class="co">#&gt; Chain 1 Iteration: 300 / 600 [ 50%]  (Warmup) </span>
<span class="co">#&gt; Chain 2 Iteration: 400 / 600 [ 66%]  (Warmup) </span>
<span class="co">#&gt; Chain 1 Iteration: 400 / 600 [ 66%]  (Warmup) </span>
<span class="co">#&gt; Chain 2 Iteration: 500 / 600 [ 83%]  (Warmup) </span>
<span class="co">#&gt; Chain 2 Iteration: 501 / 600 [ 83%]  (Sampling) </span>
<span class="co">#&gt; Chain 1 Iteration: 500 / 600 [ 83%]  (Warmup) </span>
<span class="co">#&gt; Chain 1 Iteration: 501 / 600 [ 83%]  (Sampling) </span>
<span class="co">#&gt; Chain 2 Iteration: 600 / 600 [100%]  (Sampling) </span>
<span class="co">#&gt; Chain 2 finished in 47.5 seconds.</span>
<span class="co">#&gt; Chain 1 Iteration: 600 / 600 [100%]  (Sampling) </span>
<span class="co">#&gt; Chain 1 finished in 54.2 seconds.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Both chains finished successfully.</span>
<span class="co">#&gt; Mean chain execution time: 50.8 seconds.</span>
<span class="co">#&gt; Total execution time: 54.3 seconds.</span></code></pre></div>
<p>The initial messages “The current Metropolis proposal is about to be rejected […]” can safely be ignored. However, if you see warnings about either divergences or maximum treedepth, be wary. For a brief introduction to these warnings, <a href="https://mc-stan.org/misc/warnings.html">see here</a>. You can try setting adapt_delta to a higher number, but if you reach a value like 0.99 and still encounter divergences, then it is likely that there is a deeper issue, a conflict between the model and your data.</p>
<p>Such conflicts are beyond the scope of this vignette. If increasing adapt delta does not eliminate the sampling warnings, feel free to file an issue on the <a href="https://github.com/psadil/nmmr/issues">github repository</a>. It may be possible to tailor the model to your dataset.</p>
</div>
</div>
<div id="analyzing-results" class="section level2">
<h2 class="hasAnchor">
<a href="#analyzing-results" class="anchor"></a>Analyzing Results</h2>
<p>The <a href="https://psadil.github.io/nmmr/reference/Deming.html#method-sample"><code>$sample()</code></a> method returns a <code><a href="https://mc-stan.org/cmdstanr/reference/CmdStanMCMC.html">cmdstanr::CmdStanMCMC</a></code> object. For example, we can look at a quick summary of the population-level parameters for the slope (<code>g_mu</code> and <code>g_sigma</code>), the intercept (<code>a_mu</code> and <code>a_sigma</code>), the noise at low contrast (<code>x_sigma_mu</code> and <code>x_sigma_sigma</code>), and the noise at high contrast (<code>y_sigma_mu</code> and <code>y_sigma_sigma</code>).</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit</span><span class="op">$</span><span class="fu">summary</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"g_mu"</span>, <span class="st">"g_sigma"</span>,
              <span class="st">"a_mu"</span>, <span class="st">"a_sigma"</span>,
              <span class="st">"x_sigma_mu"</span>, <span class="st">"x_sigma_sigma"</span>,
              <span class="st">"y_sigma_mu"</span>, <span class="st">"y_sigma_sigma"</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; # A tibble: 8 x 10</span>
<span class="co">#&gt;   variable       mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail</span>
<span class="co">#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 g_mu          -2.10  -2.14 2.39  1.86  -5.98   2.26 1.13      12.2     14.5</span>
<span class="co">#&gt; 2 g_sigma        3.39   3.10 1.44  1.21   1.50   5.95 1.01     115.     120. </span>
<span class="co">#&gt; 3 a_mu           2.59   2.75 1.83  1.37  -1.09   5.55 1.17      16.5     15.2</span>
<span class="co">#&gt; 4 a_sigma        2.77   2.69 1.18  1.01   0.829  4.54 1.00      66.6     59.9</span>
<span class="co">#&gt; 5 x_sigma_mu     1.39   1.37 0.833 0.947  0.134  2.65 1.01     171.     145. </span>
<span class="co">#&gt; 6 x_sigma_sigma  2.53   2.42 0.687 0.628  1.61   3.97 1.01     173.     166. </span>
<span class="co">#&gt; 7 y_sigma_mu     1.15   1.13 0.573 0.665  0.292  2.12 1.02     149.     153. </span>
<span class="co">#&gt; 8 y_sigma_sigma  1.73   1.63 0.662 0.520  0.953  2.84 0.998    210.     225.</span></code></pre></div>
<p>Additionally, we can make use of the many other packages that compose the Stan ecosystem. For example, <a href="https://mc-stan.org/bayesplot/"><code>bayesplot</code></a> has many resources for plotting posterior distributions. The following shows a pairs plot, useful for seeing whether parameters in the posterior tradeoff.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">bayesplot</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/MCMC-scatterplots.html">mcmc_pairs</a></span><span class="op">(</span>
  <span class="va">fit</span><span class="op">$</span><span class="fu">draws</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"g_mu"</span>, <span class="st">"g_sigma"</span>,
             <span class="st">"x_sigma_mu"</span>, <span class="st">"x_sigma_sigma"</span>,
             <span class="st">"y_sigma_mu"</span>, <span class="st">"y_sigma_sigma"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="figure">
<img src="deming-regression_files/figure-html/pairs-1.png" alt="These parameters do not exhibit strong correlations." width="700"><p class="caption">
These parameters do not exhibit strong correlations.
</p>
</div>
<p>For digging deeper into the model, other packages from the Stan development team will be useful. For example, if you have <a href="https://mc-stan.org/rstan/"><code>RStan</code></a> installed, you can use the function <a href="https://mc-stan.org/rstan/reference/stan_csv.html"><code>rstan::read_stan_csv()</code></a> to reformat the results and use <a href="https://mc-stan.org/shinystan/"><code>shinystan</code></a>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">stanfit</span> <span class="op">&lt;-</span> <span class="fu">rstan</span><span class="fu">::</span><span class="fu">read_stan_csv</span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="fu">output_files</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="fu">shinystan</span><span class="fu">::</span><span class="fu">launch_shinystan</span><span class="op">(</span><span class="va">stanfit</span><span class="op">)</span></code></pre></div>
<p>When applying this model to your data, it is a good idea to browse through these plots. For now, focus on the three main parameters of interest, the average noise at low and high contrast (<code>x_sigma_mu</code> and <code>y_sigma_mu</code>), and the average slope (<code>g_mu</code>). For ease of plotting, convert the posterior samples into a <code><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble::tibble</a></code>.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">draws</span> <span class="op">&lt;-</span> <span class="va">fit</span><span class="op">$</span><span class="fu">draws</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"g_mu"</span>, <span class="st">"x_sigma_mu"</span>,<span class="st">"y_sigma_mu"</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">posterior</span><span class="fu">::</span><span class="fu"><a href="https://mc-stan.org/posterior/reference/draws_df.html">as_draws_df</a></span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="op">)</span> </code></pre></div>
<p>Now use <a href="https://www.tidyverse.org/"><code>tidyverse</code></a> packages to plot the posteriors. For example, we can look at whether there is evidence that the noise differs across levels of contrast.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">draws</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">g_mu</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/pivot_longer.html">pivot_longer</a></span><span class="op">(</span>cols <span class="op">=</span> <span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">contains</a></span><span class="op">(</span><span class="st">"sigma"</span><span class="op">)</span>, names_to <span class="op">=</span> <span class="st">"Contrast"</span>, values_to <span class="op">=</span> <span class="st">"Noise"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>
    Contrast <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span>
      <span class="va">Contrast</span>, 
      levels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"x_sigma_mu"</span>, <span class="st">"y_sigma_mu"</span><span class="op">)</span>,
      labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Low"</span>, <span class="st">"High"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">Noise</span>, fill<span class="op">=</span><span class="va">Contrast</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins<span class="op">=</span><span class="fl">50</span>, position <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_dodge.html">position_dodge</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> </code></pre></div>
<div class="figure">
<img src="deming-regression_files/figure-html/post_noise-1.png" alt="These data provide some evidence that noise increases at high contrast, but the posteriors are not precise enough to be confident." width="700"><p class="caption">
These data provide some evidence that noise increases at high contrast, but the posteriors are not precise enough to be confident.
</p>
</div>
<p>Finally, what is the average slope?</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">draws</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html">contains</a></span><span class="op">(</span><span class="st">"sigma"</span><span class="op">)</span>, Slope <span class="op">=</span> <span class="st">"g_mu"</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Slope</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">50</span><span class="op">)</span> </code></pre></div>
<div class="figure">
<img src="deming-regression_files/figure-html/post_slope-1.png" alt="In support of multiplicative gain, the average slope appears to be larger than 1." width="700"><p class="caption">
In support of multiplicative gain, the average slope appears to be larger than 1.
</p>
</div>
<p>Since multiplicative gain but not additive offset predict a slope larger than 1, these data provide evidence that contrast causes multiplicative neuromodulation.</p>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>If hierarchical modeling is unfamiliar, see <a href="https://mc-stan.org/rstanarm/articles/pooling.html">here</a> for a brief introduction.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The terminology <a href="https://en.wikipedia.org/wiki/Deming_regression">“Deming”</a> refers to this later relaxation.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>The model code is also available on the <code>nmmr</code> repository, <a href="https://github.com/psadil/nmmr/blob/main/inst/stan/deming.stan">here</a>.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Alternatively, you can use <a href="https://mc-stan.org/shinystan/"><code>shinystan</code></a> without installing <a href="https://mc-stan.org/rstan/"><code>RStan</code></a> by instead installing the development version of <a href="https://mc-stan.org/shinystan/"><code>shinystan</code></a>. See <a href="https://github.com/stan-dev/shinystan/issues/184" class="uri">https://github.com/stan-dev/shinystan/issues/184</a>.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Patrick Sadil.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
